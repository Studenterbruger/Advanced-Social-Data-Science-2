{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Classification I\n",
    "\n",
    "In this exercise session, you will be training a logistic regression model to classify movie review text into positive and negative reviews. You will be using a bag-of-words approach, where the features are the TF-IDF scores of the tokens in the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Load the libraries\n",
    "\n",
    "You will need to have installed:\n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "- datasets\n",
    "- sklearn\n",
    "- wordcloud and matplotlib (optional)\n",
    "\n",
    "It is good practice to have all the imports at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Load the *rotten_tomatoes* data set\n",
    "\n",
    "This is a data set of short snippets from movie reviews on Rotten Tomatoes, along with whether the review gave the movie a positive (\"fresh\") or negative (\"rotten\") rating.\n",
    "\n",
    "1. Have a look at the [documentation](https://huggingface.co/datasets/rotten_tomatoes) of the data set on HuggingFace\n",
    "2. Load the dataset (train, validation and test splits) from the huggingface library.\n",
    "3. Print some review to have an idea of what kind of data this is.\n",
    "\n",
    "You can also browse all HF datasets visually online at [huggingface datasets](https://huggingface.co/datasets/tweet_eval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Vectorizing the reviews with TF-IDF\n",
    "\n",
    "1. Get the texts of the reviews and labels into separate lists for all the `rotten_tomatoes` data subsets\n",
    "2. Turn the texts into numbers with TFIDF vectorizer from scikit-learn.\n",
    "\n",
    "TF-IDF vectorizer documentation can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Exploratory analysis\n",
    "\n",
    "1. How many classes does this data have? Are the classes balanced?\n",
    "2. What are the top 10 frequent words in all the reviews?\n",
    "\n",
    "Hint: if you use sklearn CountVectorizer and are running out of memory, you can limit how many words to compute frequencies for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Logistic Regression\n",
    "\n",
    "1. Create the classifier and train it on the train set. If you find that it doesn't converge, try increasing the number of iterations (`max_iter` parameter), e.g. to 1500. Documentation for logistic regression can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "2. Make predictions on the validation set (leave the test set aside for now)\n",
    "3. Use the accuracy metric to compare the predicted labels to the ground truth labels you have from the original data. The documentation is [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html).\n",
    "4. Optional bonus task: scikit learn has a very useful [dummy classifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html). If your classifier were always simply predicting the majority class, how well would it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6. Testing on your own data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Find 10-20 reviews outside of this dataset. You can pick any reviews you like, from rottentomatoes.com or ones you write yourself.\n",
    "2. Put them into a spreadsheet and either manually annotate them with negative or positive sentiment, or use the labels provided on rottentomatoes.com. Make sure the columns are named \"text\" and \"label\" and the labels are consistent with the `rotten_tomatoes` markup scheme (1=positive, 0=negative).\n",
    "3. Save this file as a .csv file, load it into your notebook, convert the text to TF-IDF scores.\n",
    "4. Use this small dataset as a test dataset for the logistic regression classifier trained on the `rotten_tomatoes` data. Is your classifier doing better or worse than on the validation data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 7. Does pre-processing make a difference?\n",
    "\n",
    "Everything you've done so far was just considering the raw text of the reviews. Let us try to add pre-processing.\n",
    "\n",
    "1. What preprocessing do you think could help the classifier? Why do you think so?\n",
    "2. Implement the pre-processing step(s) of your choice and re-vectorize the rotten_tomatoes reviews.\n",
    "3. Re-run the classifier. Did the accuracy improve? Why do you think it improved (or didn't)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 8. Bonus: visualize the reviews with a word cloud\n",
    "\n",
    "Wordcloud is a nice little library to visualize text. The only required argument is the text from which the wordcloud should be generated. Removing punctuation, lowercasing and stripping English stopwords happens automatically.\n",
    "\n",
    "- [reference](https://github.com/amueller/word_cloud/blob/master/examples/simple.py)\n",
    "- [tutorial](https://www.datacamp.com/community/tutorials/wordcloud-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic usage:\n",
    "\n",
    "#type in your sentence\n",
    "sentence = ''\n",
    "wordcloud = WordCloud(background_color=\"white\",\n",
    "                      width=400\n",
    "                     ).generate(sentence)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
