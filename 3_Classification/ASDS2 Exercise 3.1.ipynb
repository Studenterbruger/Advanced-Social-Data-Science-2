{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Classification I\n",
    "\n",
    "In this exercise session, you will be training a logistic regression model to classify movie review text into positive and negative reviews. You will be using a bag-of-words approach, where the features are the TF-IDF scores of the tokens in the review."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Load the libraries\n",
    "\n",
    "You will need to have installed:\n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "- datasets\n",
    "- sklearn\n",
    "- wordcloud and matplotlib (optional)\n",
    "\n",
    "It is good practice to have all the imports at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from datasets import load_dataset, logging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Load the *rotten_tomatoes* data set\n",
    "\n",
    "This is a data set of short snippets from movie reviews on Rotten Tomatoes, along with whether the review gave the movie a positive (\"fresh\") or negative (\"rotten\") rating.\n",
    "\n",
    "1. Have a look at the [documentation](https://huggingface.co/datasets/rotten_tomatoes) of the data set on HuggingFace\n",
    "2. Load the dataset (train, validation and test splits) from the huggingface library.\n",
    "3. Print some review to have an idea of what kind of data this is.\n",
    "\n",
    "You can also browse all HF datasets visually online at [huggingface datasets](https://huggingface.co/datasets/tweet_eval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (C:/Users/asger/.cache/huggingface/datasets/rotten_tomatoes/sentiment/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Found cached dataset rotten_tomatoes (C:/Users/asger/.cache/huggingface/datasets/rotten_tomatoes/sentiment/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n",
      "Found cached dataset rotten_tomatoes (C:/Users/asger/.cache/huggingface/datasets/rotten_tomatoes/sentiment/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
     ]
    }
   ],
   "source": [
    "classification1_annotation = pd.read_csv(\"../dataset/classification1_annotation.csv\")#, compression = 'bz2')\n",
    "\n",
    "# load the 2-class sentiment classification model from rotten_tomatoes\n",
    "train = load_dataset('rotten_tomatoes', 'sentiment', split='train')\n",
    "val = load_dataset('rotten_tomatoes', 'sentiment', split='validation')\n",
    "test = load_dataset('rotten_tomatoes', 'sentiment', split='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Review Dataset.\n",
      "This is a dataset of containing 5,331 positive and 5,331 negative processed\n",
      "sentences from Rotten Tomatoes movie reviews. This data was first used in Bo\n",
      "Pang and Lillian Lee, ``Seeing stars: Exploiting class relationships for\n",
      "sentiment categorization with respect to rating scales.'', Proceedings of the\n",
      "ACL, 2005.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train.description)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Vectorizing the reviews with TF-IDF\n",
    "\n",
    "1. Get the texts of the reviews and labels into separate lists for all the `rotten_tomatoes` data subsets\n",
    "2. Turn the texts into numbers with TFIDF vectorizer from scikit-learn.\n",
    "\n",
    "TF-IDF vectorizer documentation can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = [x[\"text\"] for x in train]\n",
    "train_labels = [x[\"label\"] for x in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trains is :(8530, 16474)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_corpus)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "sparse_array = X_train.toarray()\n",
    "\n",
    "print(f\"Trains is :{X_train.shape}\")\n",
    "\n",
    "val_corpus = [x[\"text\"] for x in val]\n",
    "val_features = vectorizer.transform(val_corpus)\n",
    "val_labels = [x[\"label\"] for x in val]\n",
    "\n",
    "test_corpus = [x[\"text\"] for x in test]\n",
    "test_features = vectorizer.transform(test_corpus)\n",
    "test_labels = [x[\"label\"] for x in test]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Exploratory analysis\n",
    "\n",
    "1. How many classes does this data have? Are the classes balanced?\n",
    "2. What are the top 10 frequent words in all the reviews?\n",
    "\n",
    "Hint: if you use sklearn CountVectorizer and are running out of memory, you can limit how many words to compute frequencies for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full dataset contains 10662 instances, of which 5331 are negative, and 5331 are positive.\n"
     ]
    }
   ],
   "source": [
    "all_labels = train_labels+val_labels+test_labels\n",
    "print(f\"The full dataset contains {len(all_labels)} instances, of which {all_labels.count(0)} are negative, and {all_labels.count(1)} are positive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>10209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>6264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>6148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>4275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>3435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>3384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>2658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>but</th>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "the   10209\n",
       "and    6264\n",
       "of     6148\n",
       "to     4275\n",
       "it     3435\n",
       "is     3384\n",
       "in     2675\n",
       "that   2658\n",
       "as     1808\n",
       "but    1641"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \" \".join(train_corpus+val_corpus+test_corpus)\n",
    "#corpus = \n",
    "\n",
    "c_vectorizer = CountVectorizer()\n",
    "X = c_vectorizer.fit_transform([corpus])\n",
    "\n",
    "counts = pd.DataFrame(X.toarray(),\n",
    "                      columns=c_vectorizer.get_feature_names_out())\n",
    "\n",
    "# getting top 10 most common words\n",
    "counts.T.sort_values(by=0, ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Logistic Regression\n",
    "\n",
    "1. Create the classifier and train it on the train set. If you find that it doesn't converge, try increasing the number of iterations (`max_iter` parameter), e.g. to 1500. Documentation for logistic regression can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "2. Make predictions on the validation set (leave the test set aside for now)\n",
    "3. Use the accuracy metric to compare the predicted labels to the ground truth labels you have from the original data. The documentation is [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html).\n",
    "4. Optional bonus task: scikit learn has a very useful [dummy classifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html). If your classifier were always simply predicting the majority class, how well would it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The logistic regression has an accuracy of 0.7514071294559099\n",
      "Majority baseline accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Create logistic regression object # Train the model using the training sets\n",
    "lr = LogisticRegression(max_iter=1500).fit(X_train, train_labels) \n",
    "    # Her bruger jeg X_train, som jeg har lavet med TF-IDF \n",
    "    # og så train_labels (som er hvorvidt det var et positivt eller negativt tweet)\n",
    "\n",
    "\n",
    "# Make predictions using the testing set\n",
    "val_pred = lr.predict(val_features)\n",
    "    # Så predicter jeg på baggrund af min Logistiske regression\n",
    "\n",
    "print(f\"The logistic regression has an accuracy of {accuracy_score(val_pred, val_labels)}\")\n",
    "\n",
    "#Dummy Classifier - a \"naive baseline\" that simply predicts the majority class\n",
    "from sklearn.dummy import DummyClassifier\n",
    "majority_class = DummyClassifier(strategy= 'most_frequent').fit(X_train,train_labels)\n",
    "val_pred_majority = majority_class.predict(val_features)\n",
    "\n",
    "print(\"Majority baseline accuracy:\", accuracy_score(val_labels, val_pred_majority))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8530x16474 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 143428 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6. Testing on your own data!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Find 10-20 reviews outside of this dataset. You can pick any reviews you like, from rottentomatoes.com or ones you write yourself.\n",
    "2. Put them into a spreadsheet and either manually annotate them with negative or positive sentiment, or use the labels provided on rottentomatoes.com. Make sure the columns are named \"text\" and \"label\" and the labels are consistent with the `rotten_tomatoes` markup scheme (1=positive, 0=negative).\n",
    "3. Save this file as a .csv file, load it into your notebook, convert the text to TF-IDF scores.\n",
    "4. Use this small dataset as a test dataset for the logistic regression classifier trained on the `rotten_tomatoes` data. Is your classifier doing better or worse than on the validation data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  It's extremely sad, but imagine u have to work...      0\n",
      "1  #NLProc question about publication ethics: how...      0\n",
      "2  Some institutions I know never could afford pa...      0\n",
      "3  Looking back, I don’t see shortages & failures...      1\n",
      "4  Very excited to speak at this workshop! Defini...      1\n",
      "5  People have been asking, so I wanted to make i...      1\n",
      "6  Aerospace defence research institute of the Ru...      1\n",
      "7  i am at the stage of my life where i need to w...      0\n",
      "8  I am actually really enjoying @svpino's daily ...      1\n",
      "/n Accuracy for LR on the new test data: 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "mydata = pd.read_csv(\"../dataset/classification1_annotation.csv\")\n",
    "mydata[\"label\"] = np.where(mydata[\"label\"] == \"negative\", 0, 1) # ændre så de passer med det tidligere markup\n",
    "print(mydata.head(9))\n",
    "\n",
    "mytest_corpus= list(mydata[\"text\"])\n",
    "mytest_labels = list(mydata[\"label\"])\n",
    "mytest_features = vectorizer.transform(mytest_corpus)\n",
    "\n",
    "mytest_pred = lr.predict(mytest_features)\n",
    "print(\"/n Accuracy for LR on the new test data:\", accuracy_score(mytest_labels, mytest_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 7. Does pre-processing make a difference?\n",
    "\n",
    "Everything you've done so far was just considering the raw text of the reviews. Let us try to add pre-processing.\n",
    "\n",
    "1. What preprocessing do you think could help the classifier? Why do you think so?\n",
    "2. Implement the pre-processing step(s) of your choice and re-vectorize the rotten_tomatoes reviews.\n",
    "3. Re-run the classifier. Did the accuracy improve? Why do you think it improved (or didn't)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 8. Bonus: visualize the reviews with a word cloud\n",
    "\n",
    "Wordcloud is a nice little library to visualize text. The only required argument is the text from which the wordcloud should be generated. Removing punctuation, lowercasing and stripping English stopwords happens automatically.\n",
    "\n",
    "- [reference](https://github.com/amueller/word_cloud/blob/master/examples/simple.py)\n",
    "- [tutorial](https://www.datacamp.com/community/tutorials/wordcloud-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic usage:\n",
    "\n",
    "#type in your sentence\n",
    "sentence = ''\n",
    "wordcloud = WordCloud(background_color=\"white\",\n",
    "                      width=400\n",
    "                     ).generate(sentence)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
