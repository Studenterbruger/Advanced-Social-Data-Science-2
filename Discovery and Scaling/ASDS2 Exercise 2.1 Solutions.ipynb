{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d620639b",
   "metadata": {},
   "source": [
    "# Keyword expansion \n",
    "\n",
    "In this exercise we are going to use the keyword expansion technique propsoed in `Computer-Assisted Keyword and Document Set Discovery from Unstructured Text` by King, Lam and Roberts (2017), in order to label a dataset of tweets according to whether or not they are related to covid-19. \n",
    "\n",
    "The idea is to use an initial list of keywords to label the date, and then use supervised learning to expand the list of keywords to get a better sense of how people talk about a topic. It is an iterative approach, meaning that you start with a list of keywords, and expand it, run it again etc. until you saturate the list. The approach also emphasises that you should read some of the text that you label, in order to ensure correct labelling. \n",
    "\n",
    "\n",
    "This exercise is a python translation of Gregory Eady's R exercise, heavily inspired by the replication material found here: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/FMJDCD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf8452",
   "metadata": {},
   "source": [
    "If interested, you can also see Greg's walk-through of the R version of this code in his video here: \n",
    "https://gregoryeady.com/SocialMediaDataCourse/readings/Keywords/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae27c29",
   "metadata": {},
   "source": [
    "### Read in required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6fd13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import pyreadr #package to allow us to read in .rds data files (native R datafile)\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "from math import lgamma\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c383674",
   "metadata": {},
   "source": [
    "# 1. Load the data\n",
    "\n",
    "Read in data as usual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d322012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read a .rds file\n",
    "\n",
    "#result = pyreadr.read_r(\"MOC_Tweets.rds\") \n",
    "#df = result[None] # extract the pandas data frame \n",
    "\n",
    "\n",
    "df = pd.read_csv('MOC_Tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd09dc",
   "metadata": {},
   "source": [
    "# 1.1. Preprocessing \n",
    "\n",
    "Due to time restraints, the preprocessing code is given below, ready to be run. Take a look at the code to understand what is being done. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a5e22f",
   "metadata": {},
   "source": [
    "Subset the data by removing tweets before 2019 (we are only interested in tweets that may reference COVID-19)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13256c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.date  >= 20190101] # Subset to 2019 and later because we'll look at COVID-19 over time\n",
    "df = df.loc[df.tweet_id.drop_duplicates().index] # removing duplicate observations (tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a75022b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340dd7cd",
   "metadata": {},
   "source": [
    "Save the original text and lowercase the text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4550e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_original'] = df['text']\n",
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968cd89a",
   "metadata": {},
   "source": [
    "Do some (but not all) preprocessing by removing tweet elements that we do not care about. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943c3975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove mentions (posts that start with a \"@some_user_name \")\n",
    "df['text'] = df['text'].str.replace(\"\\\\B@\\\\w+|^@\\\\w+\", \"\", regex = True)\n",
    "# Change ampersands to \"and\"\n",
    "df['text'] = df['text'].str.replace(\"&amp;\", \"and\")\n",
    "# Remove the \"RT\" and \"via\" (old retweet style)\n",
    "df['text'] = df['text'].str.replace(\"(^RT|^via)((?:\\\\b\\\\W*@\\\\w+)+)\",\"\", regex=True, case=False)\n",
    "# Remove URLs             \n",
    "df['text'] = df['text'].str.replace(\"(https|http)?:\\\\/\\\\/(\\\\w|\\\\.|\\\\/|\\\\?|\\\\=|\\\\&|\\\\%)*\\\\b\", \"\", regex = True)\n",
    "# Keep ASCII only (removes Cyrillic, Japanese characters, etc.)\n",
    "df['text'] = df['text'].str.replace(\"[^ -~]\", \"\", regex = True)\n",
    "# Remove double+ spaces (e.g. \"build   the wall\" to \"build the wall\")\n",
    "df['text'] = df['text'].str.replace(\"\\\\s+\", \" \", regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e61ce",
   "metadata": {},
   "source": [
    "With our mostly preprocessed tweets, let us begin building our classifier from chosen keywords. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837764ab",
   "metadata": {},
   "source": [
    "# 2. Define inclusion and exclusion keywords\n",
    "\n",
    "You should now define the initial keywords that you want to include and exclude. Keywords to include should reference COVID-19, e.g. \"covid19\" and/or \"coronavirus\". We will use these initial keywords to find more keywords relevant to the topic.\n",
    "\n",
    "1. Define 4 lists: the **first** should contain a seed reference word to be included, the **second** should contain the expanded list of reference words to include (empty to begin with), the **third** should contain a seed reference word to be excluded (can be left empty), and the **fourth** should contain the expanded list of reference words to exclude (empty to begin with). \n",
    "\n",
    "2. Using `.join`, collapse the two inclusion and exclusion lists, respectively, into strings that can be used as regex OR-operations. The result should be in the form \\['dog', 'cat'\\] --> 'dog|cat'\n",
    "\n",
    "3. Use this regex string to create a bool column indicating whether the tweet contains one of your keywords.\n",
    "\n",
    "4. If you have any exlusions, also find the tweets that contain the excluded keywords (the exclusion list can be left empty). \n",
    "\n",
    "5. Define a variable that is either 0 or 1, where 1 shows that the tweet contains one or more of your inclusion keywords _and_ does not contain any exclusion keywords. Create a bool column with this. \n",
    "\n",
    "6. See how many tweets you have labelled as related to COVID-19 so far (how many 0s and how many 1s). \n",
    "\n",
    "7. Sample 10 tweets labelled as COVID-19, and read the text in them (in the text_original column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebad1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The keywords that add through the keyword discovery process\n",
    "\n",
    "reference_words_seed  = [\"covid19\"] #first word we started with\n",
    "\n",
    "#reference_words_expanded = [\"covid-19\", \"coronavirus\"] #expanded list of keywords (just to show how it works)\n",
    "reference_words_expanded = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb61902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The keywords that add through the keyword discovery process\n",
    "reference_words_excluded = [] #initial\n",
    "reference_words_excluded_expanded = [] #expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f30e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the seed words and keywords added through discovery together\n",
    "\n",
    "reference_words = reference_words_seed + reference_words_expanded\n",
    "reference_words = \"|\".join(reference_words)\n",
    "\n",
    "reference_words_excluded = reference_words_excluded + reference_words_excluded_expanded\n",
    "reference_words_excluded = \"|\".join(reference_words_excluded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2feed4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'covid19'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97fdf8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_words_excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b9eac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Will there be any keywords we want to exclude? this is simply a test \n",
    "excluded_words = len(reference_words_excluded.replace(\"|\", \"\")) > 0 #checks if there are more chars than 0, returns a bool\n",
    "\n",
    "print(excluded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9966a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find tweets that contain any keywords that we want to include\n",
    "\n",
    "df['includes'] = df['text'].str.contains(pat = reference_words, regex = True, case = False)\n",
    "\n",
    "\n",
    "# Find tweets that contain any keywords that we want to exclude\n",
    "df['excludes'] = False\n",
    "if excluded_words:\n",
    "    df['excludes']  = df.loc[df['text'].str.contains(pat = reference_words_excluded, regex = True, case = False),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60f5cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a bunch of TRUE and FALSE for the posts that include and exclude keywords\n",
    "df['reference_set'] = (df['includes']== True) & (df['excludes'] == False) #all rows with the included and without the excluded\n",
    "df['reference_set'] = df['reference_set'] *1 #make into numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac280f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    579403\n",
       "1       417\n",
       "Name: reference_set, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many of each?\n",
    "df['reference_set'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ce791",
   "metadata": {},
   "source": [
    "These are the tweets we have labelled to be about covid-19. Now let us sample some of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff4c16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.loc[df['reference_set']==1,'text_original'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1862c6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: The greatest risk for #COVID19 infection is among those who are in close contact with people who have COVID-19. Thi… https://t.co/oXeXLb7QAG\n",
      "Tweet: Want to help prevent the spread of #COVID19? Here’s what the CDC suggests: -Avoid close contact w/ people who are s… https://t.co/gRTu5lIjDE\n",
      "Tweet: Follow @OHdeptofhealth for all #COVID19 updates.  ⬇️⬇️⬇️⬇️⬇️ https://t.co/qFR9zRJP8I\n",
      "Tweet: Current understanding is #COVID19 spreads mostly from person to person through respiratory droplets produced when a… https://t.co/hAP89WxLFX\n",
      "Tweet: .@repgregwalden says we have an \"all-government approach\" to contain #COVID19, support communities and local public… https://t.co/pNEHC0oDOb\n"
     ]
    }
   ],
   "source": [
    "for i in samp:\n",
    "    print(\"Tweet:\",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bb4b20",
   "metadata": {},
   "source": [
    "# 3. Further preprocessing and vectorizing\n",
    "\n",
    "Next, we need to tokenize the data and preprocess the tokens (as opposed to the preprossesing on the full string as earlier). \n",
    "\n",
    "We will also remove all the keywords that demarcate exclusion and inclusion from the covid-19 theme. This is becasue we want the model to learn to predict the topic using other, new keywords. \n",
    "\n",
    "1. Create a new col named \"text_preprocessed\" - it should be equal the text col, but with the keywords removed (Hint: use `.str.replace()` with `regex = True`). \n",
    "\n",
    "----- \n",
    "\n",
    "To spend less time on lessons you have already been through, code for further preprocessing is provided. This code may take a few minutes to run. The steps are: \n",
    "\n",
    "2. Tokenizing. A whitespace tokenizer is used, since we want to keep words with '-'.\n",
    "\n",
    "3. Removing any tokens that are only numbers (you can remove more types of tokens if you want - up to you).\n",
    "\n",
    "4. Remove any empty strings.\n",
    "\n",
    "5. Stemming.\n",
    "\n",
    "6. Re-joining the stemmed tokens using a whitespace.\n",
    "\n",
    "7. Creating a column with the preprocessed sentences.\n",
    "\n",
    "----- \n",
    "\n",
    "8. Now you have a column  of sentences made out of stemmed and preprocessed tokens. Use a CountVectorizer to make a document term matrix based on this column. Set `min_df = 10` and `max_df = 0.999`, as well as `stop_words = 'english'` and set an appropriate `ngram_range`. \n",
    "\n",
    "NB: Do not try to make this DTM into a dataframe or np array, as you will most likely run out of memory. It is a sparse matrix that you can work with in the same way as an np.array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7971f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll remove the keywords from the tweets so that the machine learning model\n",
    "# needs to use the words in each tweet that aren't those keywords to predict\n",
    "# whether it belongs in the target set or not the target set\n",
    "\n",
    "remove_keywords_from_tweets = True\n",
    "\n",
    "#make a reg-ex list of all the inclusion and exclusion words\n",
    "\n",
    "if excluded_words: #if there are exclusion words\n",
    "    all_current_keywords = reference_words + \"|\" + reference_words_excluded\n",
    "else:\n",
    "    all_current_keywords = reference_words\n",
    "\n",
    "\n",
    "df['text_preprossed'] = df['text']\n",
    "\n",
    "if remove_keywords_from_tweets:\n",
    "    df['text_preprossed'] = df['text'].str.replace(all_current_keywords, \"\", regex = True, case = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfa51574",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhitespaceTokenizer()\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8422774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579820/579820 [03:16<00:00, 2948.00it/s]\n"
     ]
    }
   ],
   "source": [
    "pre_prossed_sents =[]\n",
    "for sent in tqdm(df['text_preprossed']):\n",
    "    words = tokenizer.tokenize(sent)\n",
    "    words = [re.sub(r'\\d+', '', word) for word in words] #removing tokens that are only words \n",
    "    words = [x for x in words if x] #removing empty strings\n",
    "    sent_stem = [ps.stem(word) for word in words]\n",
    "    \n",
    "    sent_done = \" \".join(sent_stem)\n",
    "    pre_prossed_sents.append(sent_done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d16e846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_pre_stem'] = pre_prossed_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e07fa81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider saving a csv at this time\n",
    "\n",
    "#df.to_csv('MOC_Tweets_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9df7f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df = 10,\n",
    "                           max_df = 0.999,\n",
    "                           stop_words='english',\n",
    "                          ngram_range = (1,2)) #set for larger n-grams\n",
    "\n",
    "corpus = vectorizer.fit_transform(df['text_pre_stem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1959db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTM_dict = {\"DTM\":corpus,\n",
    "               \"labels\":list(df['reference_set'])} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9502c175",
   "metadata": {},
   "source": [
    "# 4. Sample training data and make predictions\n",
    "\n",
    "Let us sample some tweets we will use to train our classifier. \n",
    "\n",
    "1) Define two lists of indices: One list containing the indices of the tweets in the reference set (those labelled as belonging to the covid-19 topic), and another list containing N sample of tweets not from the reference set (N should be either 2x the amount of tweets in the reference set or 50000, whichever is smaller).\n",
    "\n",
    "2) You now have 2 lists of indices – use these to subset the Document Term Matrix (where each row represents a tweet, and each column a token) and the reference set column in the dataframe (the labels). Define a train DTM and  a train labels object. \n",
    "\n",
    "3) Fit a cross validated lasso regression, using the DTM subset as input (X) and the reference subset as labels (y). This means that we are trying to predict whether a tweet is in the reference set using the term frequencies. (Hint:  use sklearn's `linear_model.LasssoCV()`). This may take some time (approx. 5 min, depending on the size of your train data).\n",
    "\n",
    "4) Use the fitted model to make predictions on the full DTM, and create a column in the dataframe called `predicted_raw` based on this. (Remember that the rows in the DTM correspond to the rows in the dataframe).\n",
    "\n",
    "5) The prediction outputs propabilities and not classes, so check the standard deviation of the predicion_raw column - this will check if we actually have some variance in the prediction. This is just a sanity check.\n",
    "\n",
    "6) Set a threshold of 0.25, and assign 1 or 0 to a new column called `predicted`, depending on whether the probability in `predicted_raw` is >= the threshold. (Note: Keep the threshold low if you want more tweets to get into the target set).\n",
    "\n",
    "7) Create a column called `set_var`. This variable should be == \"Reference\" if the observation is in the reference set (our original covid-19 labels), \"Target\" if it is _predicted_ to be a covid-19 related tweet (1) and \"Not target\" if it is _predicted_ not to be (0).\n",
    "\n",
    "8) Create a crosstable of the prediciton and set_var, to see how you model does (hint: use use `pd.crosstab()`). Examine the crosstab - what do the different entries mean? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b89fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine how many tweets to sample for the training data\n",
    "\n",
    "n_search = min(sum(df['reference_set']==1)* 2, 50000)\n",
    "\n",
    "#NB: Greg uses *20 - but that would take too long to run for the purposes of this exercise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e586060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of indices, indicating which belong to the reference set (those labelled to be about covid)\n",
    "#   and which do not belong to the reference set\n",
    "\n",
    "reference_ids = list(df[df['reference_set']==1].index)\n",
    "search_ids = list(df[df['reference_set']==0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25b8279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417 834 1251\n"
     ]
    }
   ],
   "source": [
    "# Taking a random sample of the search indices, i.e. those that do not belong to the reference set\n",
    "search_ids_sample = random.choices(search_ids, k=n_search)\n",
    "ids = reference_ids + search_ids_sample # putting them together to create the full list of training set indices\n",
    "\n",
    "# Checking amounts\n",
    "print(len(reference_ids),len(search_ids_sample),len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6eab5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the training data in a dict object\n",
    "DTM_train = {\"DTM\" : corpus[ids,:],\n",
    "            \"labels\": list(df['reference_set'][ids])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5d16dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the classifier\n",
    "\n",
    "#linear lasso\n",
    "#clf = linear_model.LassoCV(n_jobs=-1, verbose=1) #this was a mistake - should be log reg - small mistake though\n",
    "\n",
    "#logistic reg with lasso penalty - this will actually give probs! e\n",
    "clf = linear_model.LogisticRegressionCV(penalty=\"l1\", n_jobs = -1, solver = \"saga\", max_iter=10000, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cc2c61d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1 epochs took 0 secondsconvergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 262 epochs took 0 seconds\n",
      "convergence after 302 epochs took 0 seconds\n",
      "convergence after 271 epochs took 0 seconds\n",
      "convergence after 274 epochs took 0 seconds\n",
      "convergence after 288 epochs took 0 seconds\n",
      "convergence after 193 epochs took 1 seconds\n",
      "convergence after 218 epochs took 1 seconds\n",
      "convergence after 263 epochs took 1 seconds\n",
      "convergence after 244 epochs took 1 seconds\n",
      "convergence after 259 epochs took 1 seconds\n",
      "convergence after 1841 epochs took 6 seconds\n",
      "convergence after 2106 epochs took 7 seconds\n",
      "convergence after 2195 epochs took 7 seconds\n",
      "convergence after 2260 epochs took 7 seconds\n",
      "convergence after 2089 epochs took 8 seconds\n",
      "convergence after 1025 epochs took 5 seconds\n",
      "convergence after 1023 epochs took 6 seconds\n",
      "convergence after 1608 epochs took 7 seconds\n",
      "convergence after 1425 epochs took 7 seconds\n",
      "convergence after 1871 epochs took 9 seconds\n",
      "convergence after 411 epochs took 4 seconds\n",
      "convergence after 527 epochs took 6 seconds\n",
      "convergence after 687 epochs took 7 seconds\n",
      "convergence after 800 epochs took 9 seconds\n",
      "convergence after 843 epochs took 9 seconds\n",
      "convergence after 131 epochs took 3 seconds\n",
      "convergence after 26 epochs took 1 seconds\n",
      "convergence after 111 epochs took 3 seconds\n",
      "convergence after 15 epochs took 0 seconds\n",
      "convergence after 181 epochs took 3 seconds\n",
      "convergence after 24 epochs took 0 seconds\n",
      "convergence after 213 epochs took 4 seconds\n",
      "convergence after 208 epochs took 3 seconds\n",
      "convergence after 29 epochs took 0 seconds\n",
      "convergence after 29 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   26.9s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(max_iter=10000, n_jobs=-1, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;,\n",
       "                     verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(max_iter=10000, n_jobs=-1, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;,\n",
       "                     verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(max_iter=10000, n_jobs=-1, penalty='l1', solver='saga',\n",
       "                     verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model. This takes some time. \n",
    "\n",
    "clf.fit(DTM_train['DTM'], DTM_train['labels']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4efac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the full dataset\n",
    "\n",
    "predictions = clf.predict(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b208e450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2150656125324694"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all predictions are the same (we don't want this to be zero)\n",
    "# If so, there is a problem: potentially too few observations in the reference\n",
    "# set relative to the search set\n",
    "\n",
    "np.std(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1e26944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a threshold\n",
    "\n",
    "threshold = 0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc42e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving variables so far in a dict\n",
    "\n",
    "DTM_full = {'DTM':corpus,\n",
    "            'raw_preds': predictions,\n",
    "            'preds': (predictions > threshold) * 1 ,\n",
    "            'reference': list(df['reference_set']==1),\n",
    "            'reference_ids': reference_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc21e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict whether each tweet is in the reference set based on a predicted\n",
    "# probability, where Pr(reference_set = 1) > threshold. Keep this low if want\n",
    "# more tweets to get into the target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fe740f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_var = []\n",
    "\n",
    "for i in range(0,len(DTM_full['preds'])):\n",
    "    if i in reference_ids: #if the obs is in the reference group\n",
    "        set_var.append('Reference')\n",
    "    \n",
    "    elif DTM_full['preds'][i] == 1:\n",
    "        set_var.append('Target')\n",
    "    \n",
    "    elif DTM_full['preds'][i] == 0:\n",
    "        set_var.append('Not target')\n",
    "    \n",
    "    else:\n",
    "        set_var.append(None)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53a7c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe of predictions \n",
    "\n",
    "pred_df = pd.DataFrame([pd.Series(DTM_full['preds']),pd.Series(set_var)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28bbc5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>1</th>\n",
       "      <th>Not target</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>551631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>417</td>\n",
       "      <td>27772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "1  Not target  Reference  Target\n",
       "0                               \n",
       "0      551631          0       0\n",
       "1           0        417   27772"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking performance (only classification of the reference observations are relevant to check)\n",
    "\n",
    "pd.crosstab(pred_df[0],pred_df[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01669565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Reference/Target/Not target in the dict \n",
    "\n",
    "DTM_full['set_var'] = set_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c857ec6",
   "metadata": {},
   "source": [
    "# 5. Calculate the log likelihood as in the paper\n",
    "\n",
    "1) Create 3 sets of indices based on the `set_var` colum: one for \"Target\", one for \"Not target\" and one for \"Reference\". \n",
    "\n",
    "2) Create 3 objects for the target, not_target and reference sets, based on the DTM. These should be: for each token, how often is the given token in the set, how many documents in the set contains the given token, and the proportion of documents in the set containing the given token. (Hint: see sample code for the target set. If you want to convert to a list and not a matrix object, you can use the `.tolist()[0]`)\n",
    "\n",
    "3) Create a new dataframe, where each row is a token from the DTM (you can use `vectorizer.get_feature_names()`), with 9 cols for each of the 9 objects you just created. \n",
    "\n",
    "4) Subset the dataset by removing any observations where the terms do not appear in either the target or not_target set, thus keeping only tokens that were in the original search set (step (a) on page 979).\n",
    "\n",
    "5) Keywords go in the target list if their proportion is higher among those documents estimated to be in the reference set than not; e.g. if for the word \"pandemic\", 15% of documents predicted as target contain the word \"pandemic\" versus only 2% among those in the not_target set (step (b) on page 979). Therefore: create a new column that should be True if the token has a higher or equal proportion in the target set than in the not_target set. \n",
    "\n",
    "6) Examine the `llik` function provide and look in the paper - what does it do? \n",
    "\n",
    "7) Calculate the amount of documents in the target and the not_target set.\n",
    "\n",
    "8) Use the provided function to calculate the log likelihood for each token. Assign this to a new column in the dataframe created in step 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "158bef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 3 lists of indices\n",
    "\n",
    "target_ids = list(pd.Series(DTM_full['set_var']) == 'Target')\n",
    "not_target_ids = list(pd.Series(DTM_full['set_var']) == 'Not target')\n",
    "ref_ids = list(pd.Series(DTM_full['set_var']) == 'Reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61811aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating statistics for the target, not_target and reference sets \n",
    "\n",
    "target_freq = np.sum(DTM_full['DTM'][target_ids,:],0) #how many times is each token used in the target documents\n",
    "target_num_docs = np.sum(DTM_full['DTM'][target_ids,:] > 0, axis = 0) #how many target documents does each token appear in\n",
    "target_num_docs_prop =  target_num_docs / sum(target_ids) #proportion of target docs with each token\n",
    "\n",
    "\n",
    "not_target_freq = np.sum(DTM_full['DTM'][not_target_ids,:],0) #how many times is each token used in the not_target documents\n",
    "not_target_num_docs = np.sum(DTM_full['DTM'][not_target_ids,:]> 0,axis = 0) #how many not_target documents does each token appear in\n",
    "not_target_num_docs_prop =  not_target_num_docs / sum(not_target_ids) #proportion of not_target docs with each token\n",
    "\n",
    "\n",
    "ref_freq = np.sum(DTM_full['DTM'][ref_ids,:],0) #how many times is each token used in the reference documents\n",
    "ref_num_docs = np.sum(DTM_full['DTM'][ref_ids,:] > 0, axis = 0) #how many reference documents does each token appear in\n",
    "ref_num_docs_prop =  ref_num_docs / sum(ref_ids) #proportion of reference docs with each token\n",
    "\n",
    "\n",
    "# Saving the above in a dict \n",
    "\n",
    "d = {'target_freq' :target_freq.tolist()[0],\n",
    "    'target_num_docs': target_num_docs.tolist()[0],\n",
    "    'target_num_docs_prop': target_num_docs_prop.tolist()[0],\n",
    "    'not_target_freq':not_target_freq.tolist()[0],\n",
    "    'not_target_num_docs': not_target_num_docs.tolist()[0],\n",
    "    'not_target_num_docs_prop': not_target_num_docs_prop.tolist()[0],\n",
    "    'ref_freq':ref_freq.tolist()[0],\n",
    "    'ref_num_docs': ref_num_docs.tolist()[0],\n",
    "    'ref_num_docs_prop': ref_num_docs_prop.tolist()[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9c402f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe based on the dict and token names\n",
    "\n",
    "df_prop = pd.DataFrame(d, index=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22d4fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting observations that are target or not target at least once (probably all)\n",
    "df_prop = df_prop.loc[(df_prop['target_freq']> 0) | (df_prop['not_target_freq'] > 0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce15091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column that is True if the token has a higher or equal proportion in the target set than in the not_target set. \n",
    "df_prop['target_larger'] = df_prop['target_num_docs_prop'] >= df_prop['not_target_num_docs_prop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a278d54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_freq</th>\n",
       "      <th>target_num_docs</th>\n",
       "      <th>target_num_docs_prop</th>\n",
       "      <th>not_target_freq</th>\n",
       "      <th>not_target_num_docs</th>\n",
       "      <th>not_target_num_docs_prop</th>\n",
       "      <th>ref_freq</th>\n",
       "      <th>ref_num_docs</th>\n",
       "      <th>ref_num_docs_prop</th>\n",
       "      <th>target_larger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>__</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aandm</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aandt</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aapi</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>256</td>\n",
       "      <td>226</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zte</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuck</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>152</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg facebook</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg testifi</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131871 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     target_freq  target_num_docs  target_num_docs_prop  \\\n",
       "__                             0                0              0.000000   \n",
       "aa                             2                2              0.000072   \n",
       "aandm                          2                2              0.000072   \n",
       "aandt                          1                1              0.000036   \n",
       "aapi                          10                8              0.000288   \n",
       "...                          ...              ...                   ...   \n",
       "zte                            4                3              0.000108   \n",
       "zuck                           0                0              0.000000   \n",
       "zuckerberg                    32               32              0.001152   \n",
       "zuckerberg facebook            0                0              0.000000   \n",
       "zuckerberg testifi            12               12              0.000432   \n",
       "\n",
       "                     not_target_freq  not_target_num_docs  \\\n",
       "__                                27                   21   \n",
       "aa                                17                   16   \n",
       "aandm                             49                   49   \n",
       "aandt                             10                   10   \n",
       "aapi                             256                  226   \n",
       "...                              ...                  ...   \n",
       "zte                               37                   37   \n",
       "zuck                              11                   10   \n",
       "zuckerberg                       152                  145   \n",
       "zuckerberg facebook               13                   13   \n",
       "zuckerberg testifi                 3                    3   \n",
       "\n",
       "                     not_target_num_docs_prop  ref_freq  ref_num_docs  \\\n",
       "__                                   0.000038         0             0   \n",
       "aa                                   0.000029         0             0   \n",
       "aandm                                0.000089         0             0   \n",
       "aandt                                0.000018         0             0   \n",
       "aapi                                 0.000410         0             0   \n",
       "...                                       ...       ...           ...   \n",
       "zte                                  0.000067         0             0   \n",
       "zuck                                 0.000018         0             0   \n",
       "zuckerberg                           0.000263         0             0   \n",
       "zuckerberg facebook                  0.000024         0             0   \n",
       "zuckerberg testifi                   0.000005         0             0   \n",
       "\n",
       "                     ref_num_docs_prop  target_larger  \n",
       "__                                 0.0          False  \n",
       "aa                                 0.0           True  \n",
       "aandm                              0.0          False  \n",
       "aandt                              0.0           True  \n",
       "aapi                               0.0          False  \n",
       "...                                ...            ...  \n",
       "zte                                0.0           True  \n",
       "zuck                               0.0          False  \n",
       "zuckerberg                         0.0           True  \n",
       "zuckerberg facebook                0.0          False  \n",
       "zuckerberg testifi                 0.0           True  \n",
       "\n",
       "[131871 rows x 10 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at our new dataframe\n",
    "df_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c005dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood function\n",
    "\n",
    "def llik(target_num_docs, nottarget_num_docs, target_num_docs_total, nottarget_num_docs_total):\n",
    "    '''No docstring - you neew to see what it does :) '''\n",
    "    x1 = ((lgamma(target_num_docs + 1) + lgamma(nottarget_num_docs + 1)) -\n",
    "           lgamma(target_num_docs + nottarget_num_docs + 1 + 1))\n",
    "    x2 = ((lgamma(target_num_docs_total - target_num_docs + 1) +\n",
    "           lgamma(nottarget_num_docs_total - nottarget_num_docs + 1)) -\n",
    "           lgamma(target_num_docs_total - target_num_docs +\n",
    "          nottarget_num_docs_total - nottarget_num_docs + 1 + 1))\n",
    "    llik = x1 + x2\n",
    "    return llik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec1ff6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the total number of documents in the target and not_target sets \n",
    "\n",
    "target_num_docs_total = sum(target_ids)\n",
    "nottarget_num_docs_total =  sum(not_target_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6413a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the likelihood for each token\n",
    "\n",
    "llik_list= []\n",
    "for i in range(len(df_prop)):\n",
    "    t =df_prop['target_num_docs'][i]\n",
    "    nt =df_prop['not_target_num_docs'][i]\n",
    "    l = llik(t,nt,target_num_docs_total,nottarget_num_docs_total)\n",
    "    llik_list.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ed061e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the likelihood scores \n",
    "\n",
    "df_prop['llik'] = llik_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293ed22d",
   "metadata": {},
   "source": [
    "# 6. Examine new keywords\n",
    "\n",
    "1) Show the top 25 keywords based on highest log likelihood, where the share of documents in the target set is higher than in the not_target set (see task 5.5). These are the tokens that are most likely to differentiate between the target and not_target sets (meaning that they help the model predict covid-19 related tweets).\n",
    "\n",
    "2) Do the same with the not_target - what are these terms representative of? \n",
    "\n",
    "3) Are there any of these tokens that you want to include in the keywords? Choose 1-3 keywords that you want to include or exclude. \n",
    "\n",
    "4) For the 1-3 keywords you have found, find tweets that contain the given keyword in the original tweet text in the original dataframe. Read some tweets where the keyword is used in context - do you still want to include or exclude the keyword? \n",
    "\n",
    "5) Optional: add the new keywords to the original list at the beginning of this exercise in 2.1, and rerun the exercises until here, now including the new keywords. This is how the computer-assisted keyword discovery is used iteratively. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ff89e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_freq</th>\n",
       "      <th>target_num_docs</th>\n",
       "      <th>target_num_docs_prop</th>\n",
       "      <th>not_target_freq</th>\n",
       "      <th>not_target_num_docs</th>\n",
       "      <th>not_target_num_docs_prop</th>\n",
       "      <th>ref_freq</th>\n",
       "      <th>ref_num_docs</th>\n",
       "      <th>ref_num_docs_prop</th>\n",
       "      <th>target_larger</th>\n",
       "      <th>llik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inform</th>\n",
       "      <td>3433</td>\n",
       "      <td>3287</td>\n",
       "      <td>0.118357</td>\n",
       "      <td>1622</td>\n",
       "      <td>1616</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.079137</td>\n",
       "      <td>True</td>\n",
       "      <td>-104335.950823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respons</th>\n",
       "      <td>3295</td>\n",
       "      <td>3199</td>\n",
       "      <td>0.115188</td>\n",
       "      <td>2874</td>\n",
       "      <td>2866</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>0.074341</td>\n",
       "      <td>True</td>\n",
       "      <td>-105645.649811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronaviru</th>\n",
       "      <td>1702</td>\n",
       "      <td>1696</td>\n",
       "      <td>0.061069</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.095923</td>\n",
       "      <td>True</td>\n",
       "      <td>-106379.146232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respond</th>\n",
       "      <td>2086</td>\n",
       "      <td>1986</td>\n",
       "      <td>0.071511</td>\n",
       "      <td>1587</td>\n",
       "      <td>1576</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>True</td>\n",
       "      <td>-107747.652128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread</th>\n",
       "      <td>1232</td>\n",
       "      <td>1217</td>\n",
       "      <td>0.043821</td>\n",
       "      <td>399</td>\n",
       "      <td>398</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>0.201439</td>\n",
       "      <td>True</td>\n",
       "      <td>-108637.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>1754</td>\n",
       "      <td>1643</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>2728</td>\n",
       "      <td>2693</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>0.095923</td>\n",
       "      <td>True</td>\n",
       "      <td>-109190.803776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>882</td>\n",
       "      <td>859</td>\n",
       "      <td>0.030930</td>\n",
       "      <td>236</td>\n",
       "      <td>232</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.040767</td>\n",
       "      <td>True</td>\n",
       "      <td>-109407.840931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "      <td>0.025781</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.052758</td>\n",
       "      <td>True</td>\n",
       "      <td>-109508.747058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public health</th>\n",
       "      <td>1115</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.038888</td>\n",
       "      <td>987</td>\n",
       "      <td>978</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>True</td>\n",
       "      <td>-109553.321815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerg</th>\n",
       "      <td>1607</td>\n",
       "      <td>1491</td>\n",
       "      <td>0.053687</td>\n",
       "      <td>2980</td>\n",
       "      <td>2841</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>0.069544</td>\n",
       "      <td>True</td>\n",
       "      <td>-109565.112853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updat</th>\n",
       "      <td>1421</td>\n",
       "      <td>1368</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>2400</td>\n",
       "      <td>2391</td>\n",
       "      <td>0.004334</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.040767</td>\n",
       "      <td>True</td>\n",
       "      <td>-109641.175948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el</th>\n",
       "      <td>2122</td>\n",
       "      <td>1355</td>\n",
       "      <td>0.048790</td>\n",
       "      <td>2682</td>\n",
       "      <td>2485</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>True</td>\n",
       "      <td>-109705.209056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prevent</th>\n",
       "      <td>2027</td>\n",
       "      <td>1870</td>\n",
       "      <td>0.067334</td>\n",
       "      <td>6576</td>\n",
       "      <td>6440</td>\n",
       "      <td>0.011674</td>\n",
       "      <td>87</td>\n",
       "      <td>73</td>\n",
       "      <td>0.175060</td>\n",
       "      <td>True</td>\n",
       "      <td>-109869.056579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>risk</th>\n",
       "      <td>1460</td>\n",
       "      <td>1364</td>\n",
       "      <td>0.049114</td>\n",
       "      <td>3955</td>\n",
       "      <td>3913</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.038369</td>\n",
       "      <td>True</td>\n",
       "      <td>-110133.228641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>situat</th>\n",
       "      <td>724</td>\n",
       "      <td>712</td>\n",
       "      <td>0.025637</td>\n",
       "      <td>759</td>\n",
       "      <td>757</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.026379</td>\n",
       "      <td>True</td>\n",
       "      <td>-110286.174668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>1217</td>\n",
       "      <td>798</td>\n",
       "      <td>0.028734</td>\n",
       "      <td>1483</td>\n",
       "      <td>1181</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>True</td>\n",
       "      <td>-110319.553031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>2293</td>\n",
       "      <td>2124</td>\n",
       "      <td>0.076480</td>\n",
       "      <td>12745</td>\n",
       "      <td>12064</td>\n",
       "      <td>0.021870</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>True</td>\n",
       "      <td>-110381.954624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>center</th>\n",
       "      <td>1521</td>\n",
       "      <td>1273</td>\n",
       "      <td>0.045838</td>\n",
       "      <td>4635</td>\n",
       "      <td>4413</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>True</td>\n",
       "      <td>-110397.829700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outbreak</th>\n",
       "      <td>371</td>\n",
       "      <td>360</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.033573</td>\n",
       "      <td>True</td>\n",
       "      <td>-110553.632093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepar</th>\n",
       "      <td>832</td>\n",
       "      <td>798</td>\n",
       "      <td>0.028734</td>\n",
       "      <td>2259</td>\n",
       "      <td>2232</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.023981</td>\n",
       "      <td>True</td>\n",
       "      <td>-110682.044642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>packag</th>\n",
       "      <td>602</td>\n",
       "      <td>583</td>\n",
       "      <td>0.020992</td>\n",
       "      <td>1000</td>\n",
       "      <td>993</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>True</td>\n",
       "      <td>-110690.404614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>que</th>\n",
       "      <td>763</td>\n",
       "      <td>555</td>\n",
       "      <td>0.019984</td>\n",
       "      <td>1258</td>\n",
       "      <td>908</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>True</td>\n",
       "      <td>-110712.643947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testifi</th>\n",
       "      <td>727</td>\n",
       "      <td>699</td>\n",
       "      <td>0.025169</td>\n",
       "      <td>1794</td>\n",
       "      <td>1774</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>True</td>\n",
       "      <td>-110732.479052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>1608</td>\n",
       "      <td>860</td>\n",
       "      <td>0.030966</td>\n",
       "      <td>4178</td>\n",
       "      <td>2966</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>True</td>\n",
       "      <td>-110749.076100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>2919</td>\n",
       "      <td>2454</td>\n",
       "      <td>0.088362</td>\n",
       "      <td>24030</td>\n",
       "      <td>20308</td>\n",
       "      <td>0.036814</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0.062350</td>\n",
       "      <td>True</td>\n",
       "      <td>-110771.355506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               target_freq  target_num_docs  target_num_docs_prop  \\\n",
       "inform                3433             3287              0.118357   \n",
       "respons               3295             3199              0.115188   \n",
       "coronaviru            1702             1696              0.061069   \n",
       "respond               2086             1986              0.071511   \n",
       "spread                1232             1217              0.043821   \n",
       "case                  1754             1643              0.059160   \n",
       "monitor                882              859              0.030930   \n",
       "coronavirus            716              716              0.025781   \n",
       "public health         1115             1080              0.038888   \n",
       "emerg                 1607             1491              0.053687   \n",
       "updat                 1421             1368              0.049258   \n",
       "el                    2122             1355              0.048790   \n",
       "prevent               2027             1870              0.067334   \n",
       "risk                  1460             1364              0.049114   \n",
       "situat                 724              712              0.025637   \n",
       "en                    1217              798              0.028734   \n",
       "public                2293             2124              0.076480   \n",
       "center                1521             1273              0.045838   \n",
       "outbreak               371              360              0.012963   \n",
       "prepar                 832              798              0.028734   \n",
       "packag                 602              583              0.020992   \n",
       "que                    763              555              0.019984   \n",
       "testifi                727              699              0.025169   \n",
       "la                    1608              860              0.030966   \n",
       "health                2919             2454              0.088362   \n",
       "\n",
       "               not_target_freq  not_target_num_docs  not_target_num_docs_prop  \\\n",
       "inform                    1622                 1616                  0.002929   \n",
       "respons                   2874                 2866                  0.005196   \n",
       "coronaviru                  19                   19                  0.000034   \n",
       "respond                   1587                 1576                  0.002857   \n",
       "spread                     399                  398                  0.000721   \n",
       "case                      2728                 2693                  0.004882   \n",
       "monitor                    236                  232                  0.000421   \n",
       "coronavirus                 63                   63                  0.000114   \n",
       "public health              987                  978                  0.001773   \n",
       "emerg                     2980                 2841                  0.005150   \n",
       "updat                     2400                 2391                  0.004334   \n",
       "el                        2682                 2485                  0.004505   \n",
       "prevent                   6576                 6440                  0.011674   \n",
       "risk                      3955                 3913                  0.007094   \n",
       "situat                     759                  757                  0.001372   \n",
       "en                        1483                 1181                  0.002141   \n",
       "public                   12745                12064                  0.021870   \n",
       "center                    4635                 4413                  0.008000   \n",
       "outbreak                    63                   62                  0.000112   \n",
       "prepar                    2259                 2232                  0.004046   \n",
       "packag                    1000                  993                  0.001800   \n",
       "que                       1258                  908                  0.001646   \n",
       "testifi                   1794                 1774                  0.003216   \n",
       "la                        4178                 2966                  0.005377   \n",
       "health                   24030                20308                  0.036814   \n",
       "\n",
       "               ref_freq  ref_num_docs  ref_num_docs_prop  target_larger  \\\n",
       "inform               33            33           0.079137           True   \n",
       "respons              33            31           0.074341           True   \n",
       "coronaviru           40            40           0.095923           True   \n",
       "respond              18            18           0.043165           True   \n",
       "spread               84            84           0.201439           True   \n",
       "case                 41            40           0.095923           True   \n",
       "monitor              17            17           0.040767           True   \n",
       "coronavirus          22            22           0.052758           True   \n",
       "public health        15            15           0.035971           True   \n",
       "emerg                30            29           0.069544           True   \n",
       "updat                17            17           0.040767           True   \n",
       "el                    5             5           0.011990           True   \n",
       "prevent              87            73           0.175060           True   \n",
       "risk                 16            16           0.038369           True   \n",
       "situat               11            11           0.026379           True   \n",
       "en                    2             2           0.004796           True   \n",
       "public               24            24           0.057554           True   \n",
       "center                8             7           0.016787           True   \n",
       "outbreak             14            14           0.033573           True   \n",
       "prepar               10            10           0.023981           True   \n",
       "packag               18            18           0.043165           True   \n",
       "que                   1             1           0.002398           True   \n",
       "testifi               2             2           0.004796           True   \n",
       "la                    2             2           0.004796           True   \n",
       "health               26            26           0.062350           True   \n",
       "\n",
       "                        llik  \n",
       "inform        -104335.950823  \n",
       "respons       -105645.649811  \n",
       "coronaviru    -106379.146232  \n",
       "respond       -107747.652128  \n",
       "spread        -108637.000908  \n",
       "case          -109190.803776  \n",
       "monitor       -109407.840931  \n",
       "coronavirus   -109508.747058  \n",
       "public health -109553.321815  \n",
       "emerg         -109565.112853  \n",
       "updat         -109641.175948  \n",
       "el            -109705.209056  \n",
       "prevent       -109869.056579  \n",
       "risk          -110133.228641  \n",
       "situat        -110286.174668  \n",
       "en            -110319.553031  \n",
       "public        -110381.954624  \n",
       "center        -110397.829700  \n",
       "outbreak      -110553.632093  \n",
       "prepar        -110682.044642  \n",
       "packag        -110690.404614  \n",
       "que           -110712.643947  \n",
       "testifi       -110732.479052  \n",
       "la            -110749.076100  \n",
       "health        -110771.355506  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prop.loc[df_prop['target_larger'] == True].sort_values('llik',ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a73a083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_freq</th>\n",
       "      <th>target_num_docs</th>\n",
       "      <th>target_num_docs_prop</th>\n",
       "      <th>not_target_freq</th>\n",
       "      <th>not_target_num_docs</th>\n",
       "      <th>not_target_num_docs_prop</th>\n",
       "      <th>ref_freq</th>\n",
       "      <th>ref_num_docs</th>\n",
       "      <th>ref_num_docs_prop</th>\n",
       "      <th>target_larger</th>\n",
       "      <th>llik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rt</th>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>64173</td>\n",
       "      <td>63998</td>\n",
       "      <td>0.116016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>False</td>\n",
       "      <td>-109475.916093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>475</td>\n",
       "      <td>461</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>49248</td>\n",
       "      <td>44062</td>\n",
       "      <td>0.079876</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.019185</td>\n",
       "      <td>False</td>\n",
       "      <td>-110424.500543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>474</td>\n",
       "      <td>468</td>\n",
       "      <td>0.016852</td>\n",
       "      <td>46651</td>\n",
       "      <td>43116</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>False</td>\n",
       "      <td>-110475.008986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presid</th>\n",
       "      <td>386</td>\n",
       "      <td>378</td>\n",
       "      <td>0.013611</td>\n",
       "      <td>39376</td>\n",
       "      <td>36278</td>\n",
       "      <td>0.065765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-110616.981515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honor</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>21234</td>\n",
       "      <td>20348</td>\n",
       "      <td>0.036887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-110641.241836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>344</td>\n",
       "      <td>337</td>\n",
       "      <td>0.012135</td>\n",
       "      <td>33712</td>\n",
       "      <td>31645</td>\n",
       "      <td>0.057366</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-110742.917484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>240</td>\n",
       "      <td>238</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>28695</td>\n",
       "      <td>27395</td>\n",
       "      <td>0.049662</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-110756.560849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>316</td>\n",
       "      <td>308</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>29298</td>\n",
       "      <td>27101</td>\n",
       "      <td>0.049129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>False</td>\n",
       "      <td>-110881.698018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>american</th>\n",
       "      <td>965</td>\n",
       "      <td>946</td>\n",
       "      <td>0.034063</td>\n",
       "      <td>49308</td>\n",
       "      <td>45944</td>\n",
       "      <td>0.083288</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>False</td>\n",
       "      <td>-110943.619346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nation</th>\n",
       "      <td>552</td>\n",
       "      <td>544</td>\n",
       "      <td>0.019588</td>\n",
       "      <td>35542</td>\n",
       "      <td>33288</td>\n",
       "      <td>0.060345</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>False</td>\n",
       "      <td>-110955.286783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impeach</th>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>15814</td>\n",
       "      <td>14543</td>\n",
       "      <td>0.026364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-111017.890429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>1250</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>54849</td>\n",
       "      <td>50892</td>\n",
       "      <td>0.092257</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>False</td>\n",
       "      <td>-111025.510721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>1791</td>\n",
       "      <td>1764</td>\n",
       "      <td>0.063517</td>\n",
       "      <td>66649</td>\n",
       "      <td>64947</td>\n",
       "      <td>0.117736</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.047962</td>\n",
       "      <td>False</td>\n",
       "      <td>-111036.121191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presid trump</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>11729</td>\n",
       "      <td>11510</td>\n",
       "      <td>0.020865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-111072.332885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>677</td>\n",
       "      <td>607</td>\n",
       "      <td>0.021857</td>\n",
       "      <td>37987</td>\n",
       "      <td>31187</td>\n",
       "      <td>0.056536</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>False</td>\n",
       "      <td>-111090.908781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>democrat</th>\n",
       "      <td>282</td>\n",
       "      <td>277</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>20831</td>\n",
       "      <td>19826</td>\n",
       "      <td>0.035941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-111116.842636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happi</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>10875</td>\n",
       "      <td>10616</td>\n",
       "      <td>0.019245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-111124.887581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>297</td>\n",
       "      <td>263</td>\n",
       "      <td>0.009470</td>\n",
       "      <td>22553</td>\n",
       "      <td>18502</td>\n",
       "      <td>0.033541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-111147.276759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>everi</th>\n",
       "      <td>201</td>\n",
       "      <td>199</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>16763</td>\n",
       "      <td>15958</td>\n",
       "      <td>0.028929</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>False</td>\n",
       "      <td>-111157.324511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <td>1159</td>\n",
       "      <td>1148</td>\n",
       "      <td>0.041337</td>\n",
       "      <td>44802</td>\n",
       "      <td>43569</td>\n",
       "      <td>0.078982</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>False</td>\n",
       "      <td>-111169.284291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fight</th>\n",
       "      <td>371</td>\n",
       "      <td>368</td>\n",
       "      <td>0.013251</td>\n",
       "      <td>21667</td>\n",
       "      <td>20728</td>\n",
       "      <td>0.037576</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>False</td>\n",
       "      <td>-111189.888133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celebr</th>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>10487</td>\n",
       "      <td>10175</td>\n",
       "      <td>0.018445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-111197.616738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>america</th>\n",
       "      <td>275</td>\n",
       "      <td>273</td>\n",
       "      <td>0.009830</td>\n",
       "      <td>17709</td>\n",
       "      <td>17042</td>\n",
       "      <td>0.030894</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>False</td>\n",
       "      <td>-111210.587135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>million</th>\n",
       "      <td>194</td>\n",
       "      <td>190</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>14338</td>\n",
       "      <td>13393</td>\n",
       "      <td>0.024279</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>False</td>\n",
       "      <td>-111239.960956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join</th>\n",
       "      <td>661</td>\n",
       "      <td>658</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>27264</td>\n",
       "      <td>26943</td>\n",
       "      <td>0.048842</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>False</td>\n",
       "      <td>-111256.856839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              target_freq  target_num_docs  target_num_docs_prop  \\\n",
       "rt                    434              434              0.015627   \n",
       "wa                    475              461              0.016599   \n",
       "trump                 474              468              0.016852   \n",
       "presid                386              378              0.013611   \n",
       "honor                  43               43              0.001548   \n",
       "year                  344              337              0.012135   \n",
       "great                 240              238              0.008570   \n",
       "day                   316              308              0.011090   \n",
       "american              965              946              0.034063   \n",
       "nation                552              544              0.019588   \n",
       "impeach                86               83              0.002989   \n",
       "work                 1250             1219              0.043893   \n",
       "today                1791             1764              0.063517   \n",
       "presid trump           47               47              0.001692   \n",
       "hi                    677              607              0.021857   \n",
       "democrat              282              277              0.009974   \n",
       "happi                  52               52              0.001872   \n",
       "women                 297              263              0.009470   \n",
       "everi                 201              199              0.007165   \n",
       "thank                1159             1148              0.041337   \n",
       "fight                 371              368              0.013251   \n",
       "celebr                 78               78              0.002809   \n",
       "america               275              273              0.009830   \n",
       "million               194              190              0.006841   \n",
       "join                  661              658              0.023693   \n",
       "\n",
       "              not_target_freq  not_target_num_docs  not_target_num_docs_prop  \\\n",
       "rt                      64173                63998                  0.116016   \n",
       "wa                      49248                44062                  0.079876   \n",
       "trump                   46651                43116                  0.078161   \n",
       "presid                  39376                36278                  0.065765   \n",
       "honor                   21234                20348                  0.036887   \n",
       "year                    33712                31645                  0.057366   \n",
       "great                   28695                27395                  0.049662   \n",
       "day                     29298                27101                  0.049129   \n",
       "american                49308                45944                  0.083288   \n",
       "nation                  35542                33288                  0.060345   \n",
       "impeach                 15814                14543                  0.026364   \n",
       "work                    54849                50892                  0.092257   \n",
       "today                   66649                64947                  0.117736   \n",
       "presid trump            11729                11510                  0.020865   \n",
       "hi                      37987                31187                  0.056536   \n",
       "democrat                20831                19826                  0.035941   \n",
       "happi                   10875                10616                  0.019245   \n",
       "women                   22553                18502                  0.033541   \n",
       "everi                   16763                15958                  0.028929   \n",
       "thank                   44802                43569                  0.078982   \n",
       "fight                   21667                20728                  0.037576   \n",
       "celebr                  10487                10175                  0.018445   \n",
       "america                 17709                17042                  0.030894   \n",
       "million                 14338                13393                  0.024279   \n",
       "join                    27264                26943                  0.048842   \n",
       "\n",
       "              ref_freq  ref_num_docs  ref_num_docs_prop  target_larger  \\\n",
       "rt                   3             3           0.007194          False   \n",
       "wa                   8             8           0.019185          False   \n",
       "trump                2             2           0.004796          False   \n",
       "presid               0             0           0.000000          False   \n",
       "honor                0             0           0.000000          False   \n",
       "year                 0             0           0.000000          False   \n",
       "great                0             0           0.000000          False   \n",
       "day                  2             2           0.004796          False   \n",
       "american             6             6           0.014388          False   \n",
       "nation               1             1           0.002398          False   \n",
       "impeach              0             0           0.000000          False   \n",
       "work                24            24           0.057554          False   \n",
       "today               20            20           0.047962          False   \n",
       "presid trump         0             0           0.000000          False   \n",
       "hi                   1             1           0.002398          False   \n",
       "democrat             0             0           0.000000          False   \n",
       "happi                0             0           0.000000          False   \n",
       "women                0             0           0.000000          False   \n",
       "everi                3             3           0.007194          False   \n",
       "thank                6             6           0.014388          False   \n",
       "fight                5             5           0.011990          False   \n",
       "celebr               0             0           0.000000          False   \n",
       "america              3             3           0.007194          False   \n",
       "million              1             1           0.002398          False   \n",
       "join                 7             7           0.016787          False   \n",
       "\n",
       "                       llik  \n",
       "rt           -109475.916093  \n",
       "wa           -110424.500543  \n",
       "trump        -110475.008986  \n",
       "presid       -110616.981515  \n",
       "honor        -110641.241836  \n",
       "year         -110742.917484  \n",
       "great        -110756.560849  \n",
       "day          -110881.698018  \n",
       "american     -110943.619346  \n",
       "nation       -110955.286783  \n",
       "impeach      -111017.890429  \n",
       "work         -111025.510721  \n",
       "today        -111036.121191  \n",
       "presid trump -111072.332885  \n",
       "hi           -111090.908781  \n",
       "democrat     -111116.842636  \n",
       "happi        -111124.887581  \n",
       "women        -111147.276759  \n",
       "everi        -111157.324511  \n",
       "thank        -111169.284291  \n",
       "fight        -111189.888133  \n",
       "celebr       -111197.616738  \n",
       "america      -111210.587135  \n",
       "million      -111239.960956  \n",
       "join         -111256.856839  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prop.loc[df_prop['target_larger'] == False].sort_values('llik',ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adce70b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def see_in_context(term):\n",
    "    '''Gets the tweets orginial text with the term - also supports regex - seachers the full tect\n",
    "    only returns tweets not in the orginial reference list'''\n",
    "    if vectorizer.get_feature_names_out().any():\n",
    "        subset = df.loc[(df['text_original'].str.contains(pat = term,regex = True, case = False)) & (df['reference_set'] == False),'text_original']\n",
    "        if len(subset) != 0:\n",
    "            return subset\n",
    "        else:\n",
    "            print(\"This is not a term in the corpus\")\n",
    "\n",
    "    else:\n",
    "        print(\"This is not a term in the corpus\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50891f87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202       .@AmericanLegion rightfully prides itself on b...\n",
       "458       Stemming the #opioidcrisis tide requires enfor...\n",
       "491       One of the federal government's most fundament...\n",
       "510       Recovering from a disaster takes time &amp; re...\n",
       "722       Watch: @SenJohnHoeven and I discuss why servin...\n",
       "                                ...                        \n",
       "578828    The safety of Americans at home and abroad is ...\n",
       "578976    We have a moral responsibility to future gener...\n",
       "579060    RT @RepKinzinger: Dear Left: There won’t be an...\n",
       "579067    Yesterday, @VP Pence spoke to us about the adm...\n",
       "579620    I’m disappointed to learn of the layoffs in Sl...\n",
       "Name: text_original, Length: 7876, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see_in_context(\"respons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebb9bb3",
   "metadata": {},
   "source": [
    "# 7. Optional: Use your new classifier for downstream tasks\n",
    "\n",
    "1) Assign a `final_classification` boolean column in the original dataframe, which should be 1 if the tweet contains any of the keywords in the new, complete list and if it does not contain any of the exclusion keywords. \n",
    "\n",
    "2) Examine the value counts of the political affiliation variable. Assign \"Democrat\" to the tweets labelled with \"Independent\" (see the people behind the tweets for reason).\n",
    "\n",
    "3) Plot the share of tweets labelled as covid-19 relevant by your classifier (y), grouped on days (x) for each party - meaning two lines of covid-19 share across time. \n",
    "\n",
    "**Hints:** <br>\n",
    "The pandas `groupby` functionality may be of help to you. <br>\n",
    "You can also also turn the date ints into so-called datetime objects using this:\n",
    "\n",
    "`dates =[datetime.datetime(year=int(x[i][0:4]), month=int(x[i][4:6]), day=int(x[i][6:8])) for i in range(len(x))]`\n",
    "\n",
    "where x is a list of the unique dates as int. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "61f4bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We saved no exclusion keywords so far, so this is just a look up of the terms in the preprocessed dataset\n",
    "\n",
    "df['final_calssification'] = df['text'].str.contains(pat = reference_words, regex = True, case = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dca320a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Democrat       369593\n",
       "Republican     208158\n",
       "Independent      2069\n",
       "Name: affiliation, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking political affiliations of tweeters\n",
    "\n",
    "df.affiliation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "955f3d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the independents to democrats \n",
    "\n",
    "df.loc[df['affiliation'] == \"Independent\",'affiliation'] = \"Democrat\" #the only independets are dems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc8740c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Democrat      371662\n",
       "Republican    208158\n",
       "Name: affiliation, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking that it worked\n",
    "\n",
    "df.affiliation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "804ee263",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_df = df.loc[(df['date'] > 20200101) & (df['date'] < 20200307)] #remove last day as it seems to have fewer tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2720e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_3548\\4169470675.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  y_dem_freq_cov = list(plt_df.loc[df['affiliation'] == 'Democrat',:].groupby(['date']).sum().iloc[:,-1])\n",
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_3548\\4169470675.py:8: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  y_rep_freq_cov = list(plt_df.loc[df['affiliation'] == 'Republican',:].groupby(['date']).sum().iloc[:,-1])\n"
     ]
    }
   ],
   "source": [
    "# Grouping by affiliation and date to create y values\n",
    "\n",
    "y_dem_freq_cov = list(plt_df.loc[df['affiliation'] == 'Democrat',:].groupby(['date']).sum().iloc[:,-1])\n",
    "y_dem_freq_total = list(plt_df.loc[df['affiliation'] == 'Democrat',:].groupby(['date']).count().iloc[:,-1])\n",
    "\n",
    "y_dem = [i / j for i, j in zip(y_dem_freq_cov,  y_dem_freq_total)]\n",
    "\n",
    "y_rep_freq_cov = list(plt_df.loc[df['affiliation'] == 'Republican',:].groupby(['date']).sum().iloc[:,-1])\n",
    "y_rep_freq_total = list(plt_df.loc[df['affiliation'] == 'Republican',:].groupby(['date']).count().iloc[:,-1])\n",
    "\n",
    "y_rep = [i / j for i, j in zip(y_rep_freq_cov,  y_rep_freq_total)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3188402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is the dates\n",
    "x = np.sort(plt_df.date.unique()).astype(int).astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8311c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates =[datetime.datetime(year=int(x[i][0:4]), month=int(x[i][4:6]), day=int(x[i][6:8])) for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5725e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the distribution of tweeting about covid-19 across democrats and republicans\n",
    "\n",
    "plt.plot(dates,y_dem, label = \"Democrats\", color = \"Blue\")\n",
    "plt.plot(dates,y_rep, label = \"Republicans\", color = \"Red\")\n",
    "\n",
    "plt.ylabel(\"Share of covid-19 tweets\")\n",
    "plt.xlabel('Day')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
