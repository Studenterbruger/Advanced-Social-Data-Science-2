{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages \n",
    "\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noter undervisning\n",
    "- 13-16 juni. \n",
    "- Hovy books come from NLP data tradtion\n",
    "- the other come from text as data, data tradition. \n",
    "- zipf law: the highly infrequent words represent a very large part of the meaning of a text (zipf law slide 25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Social Data Science 2 (ASDS2) Exercises\n",
    "\n",
    "\n",
    "## Overview and regular expressions\n",
    "\n",
    "### 1: Thinking about text as data\n",
    "\n",
    "Go to Kaggle’s database of text data sets here: https://www.kaggle.com/datasets?topic=nlpDatasets \n",
    "\n",
    "1. Find an interesting data set. (Try searching the data sets or playing around with the sorting rule in the top right). It doesn’t have to be social sciencey, just whatever looks interesting to you.\n",
    "2. Describe the variables in the data. What’s there in addition to the text itself, if anything?\n",
    "3. What’s a meaningful latent variable which might vary across the texts? (For example, ‘sentiment’ might plausibly vary across movie reviews).\n",
    "4. Assume you could measure the latent variable from (3). How might that latent variable correlate with other properties of the units of the data? (These can be observed variables in the data, or other, unobserved properties).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Importing text data\n",
    "\n",
    "1. The file mach.csv, available at the course Absalon page, contains part of Machiavelli’s The Prince, subdivided into 188 sections. Download it to your computer.\n",
    "2. Import the file into Python using read_csv() from pandas \n",
    "3. Using the search function from Python’s re module (or a Pandas equivalent), find out in which section(s) the following terms appear:\n",
    "    - lion\n",
    "    - flatterers\n",
    "    - ccmnot\n",
    "4. Why might a nonsensical term like ‘ccmnot’ be in the corpus?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of lions is 8, amount of mentions of flatterers is 0, amount of mentions of ccmnot is 1\n"
     ]
    }
   ],
   "source": [
    "# Loader dataset\n",
    "MTP_df = pd.read_csv(\"../dataset/mach.csv\")\n",
    "\n",
    "# Laver funktion\n",
    "def true_reg(reg, text):\n",
    "    t = re.search(reg, text)\n",
    "    if t != None:\n",
    "        return(True)\n",
    "\n",
    "# Laver reg for alle tre ord\n",
    "lion_r,flatteres_r,ccmnot_r = re.compile(\"lion\"), re.compile(\"flatteres\"), re.compile(\"ccmnot\")\n",
    "\n",
    "# Gemmer så jeg kan tælle hvert gang et af ordene forekommer\n",
    "count_lion = 0\n",
    "count_flatterers = 0 # Tror der er et eller andet med at denne måske først dukker frem når man laver en bestemt ting med datasættet\n",
    "count_ccmnot = 0\n",
    "\n",
    "# Køre for-loop med min funktion og for alle tre \n",
    "for x in MTP_df[\"text\"]:\n",
    "    lion_true = true_reg(lion_r, x)\n",
    "    flatterers_true = true_reg(flatteres_r, x)\n",
    "    ccmnot_true = true_reg(ccmnot_r, x)\n",
    "    if lion_true==True:\n",
    "        count_lion += 1\n",
    "    if flatterers_true==True:\n",
    "        count_flatterers += 1\n",
    "    if ccmnot_true==True:\n",
    "     #   print(x)\n",
    "        count_ccmnot += 1 \n",
    "\n",
    "# Printer svar\n",
    "print(f\"Amount of lions is {count_lion}, amount of mentions of flatterers is {count_flatterers}, amount of mentions of ccmnot is {count_ccmnot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Regular expressions\n",
    "\n",
    "In this exercise, we’re continuing with Python’s re module. \n",
    "<br>The following can be solved using one or more from these three functions in re:\n",
    "`search`\n",
    "`split`\n",
    "`sub`\n",
    "\n",
    "1. Define a string and check that it contains only a certain set of characters (in this case a-z, A-Z and 0-9). \n",
    "2. Define a string and check that it has an a followed by zero or more b's.\n",
    "3. Define a string and check that it has an a followed by one or more b's.\n",
    "4. Using the sample string ‘The quick brown fox jumps over the lazy dog’, search for the words 'fox', 'dog', 'horse'.\n",
    "5. Define a string with the word ‘Road’ in it, and abbreviate 'Road' as 'Rd.' using sub().\n",
    "6. Define a string and perform very simple tokenization by splitting at all whitespaces.\n",
    "7. Define a string and replace whitespaces with an underscore. After, reverse this by replacing underscores with a whitespace.\n",
    "8. Define a string with a few cases of multiple spaces between words and remove all those cases.\n",
    "\n",
    "Hint: Take a look at the documentation for Python's re module to find solutions, and test your regular expression on regextester.com or consult regex101.com \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Somthing about Road' is now modified to: 'Somthing about Rd'\n"
     ]
    }
   ],
   "source": [
    "## 1\n",
    "S_1 = \"Asger og Esben er i lokale nr. 10\"\n",
    "\n",
    "## 2\n",
    "\n",
    "## 3\n",
    "\n",
    "## 4\n",
    "\n",
    "## 5\n",
    "S_5 = \"Somthing about Road\"\n",
    "S_5_modified = re.sub('Road', 'Rd', S_5)\n",
    "print(f\"'{S_5}' is now modified to: '{S_5_modified}'\")\n",
    "\n",
    "## 6\n",
    "S_6 = \"Ny tekst som jeg skriver igen her for at kunne splitte\"\n",
    "S_6_modified = re.split(\" \", S_6)\n",
    "\n",
    "## 7\n",
    "S_7 = \"Ny tekst som jeg skriver igen her for at kunne splitte\"\n",
    "S_7_modified = re.sub(\"_\", \" \", re.sub(\" \", \"_\", S_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ny tekst som jeg skriver igen her for at kunne splitte'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_7_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana#cherry#orange']\n"
     ]
    }
   ],
   "source": [
    "txt = \"apple#banana#cherry#orange\"\n",
    "\n",
    "# setting the maxsplit parameter to 1, will return a list with 2 elements!\n",
    "x = txt.split(\"#\", 1)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I xm x humxn being.\n",
      "x xm x humxn being.\n"
     ]
    }
   ],
   "source": [
    "# Given String\n",
    "s = \"I am a human being.\"\n",
    "\n",
    "# Performing Sub() operation\n",
    "res_1 = re.sub('a', 'x', s)\n",
    "res_2 = re.sub('[a,I]','x',s)\n",
    "\n",
    "# Print Results\n",
    "print(res_1)\n",
    "print(res_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
